{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "points[1:, 0] #all rows after the first, first column\n",
    "points[2:, 1] #all rows after the second, second column- only one entry. 6\n",
    "#points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(2,3)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3538, -1.3923, -1.1282, -2.3586,  0.0555],\n",
       "        [-0.3133, -0.1028, -0.7182, -0.4969,  0.2671],\n",
       "        [ 2.2092, -0.0409,  1.7905, -0.4240,  0.9849],\n",
       "        [-0.8076, -1.3662, -0.5117, -0.3452, -0.9885],\n",
       "        [-0.2870,  2.0360,  0.5162, -0.6286,  0.1478]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example tensor that we might expect from an image- [channels, rows, columns]\n",
    "img_t = torch.randn(3,5,5)\n",
    "img_t[0] #R\n",
    "img_t[1] #G\n",
    "img_t[2] #B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5006, -1.2501, -0.2773,  0.8128, -2.3660],\n",
       "        [-0.5298,  0.6228, -1.5704, -0.0873,  0.2272],\n",
       "        [ 1.4160,  0.5330, -1.0560,  0.2732,  0.1806],\n",
       "        [ 0.2043,  2.3236,  2.2123, -1.4864,  2.1949],\n",
       "        [-0.3786,  1.2157,  1.1916, -0.5246,  1.4528]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Img batch! [batch, channel, row, colum]\n",
    "batch_t = torch.randn(2, 3, 5, 5)\n",
    "batch_t[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.9075e-01, -5.2675e-01,  4.6761e-01, -4.2985e-01, -5.0401e-01],\n",
       "         [ 2.5349e-01, -1.0263e+00, -3.8318e-02,  5.4191e-01, -8.2166e-02],\n",
       "         [ 1.2039e+00,  7.4511e-01,  4.3496e-01,  6.1954e-02,  6.2730e-01],\n",
       "         [-5.7429e-01,  6.7650e-02,  4.2046e-02, -8.2288e-01, -4.3171e-01],\n",
       "         [ 4.4459e-01,  8.3897e-01, -1.5368e-01, -1.1578e-03,  1.3813e-01]]),\n",
       " tensor([[[-0.1969, -0.9613,  0.1971,  0.8441, -1.2041],\n",
       "          [-0.0379,  0.6655, -0.0739, -0.0781,  0.0054],\n",
       "          [-0.2723,  0.3422,  0.1041, -0.7682,  0.2391],\n",
       "          [ 0.2425,  1.2912,  0.5904, -0.7433,  0.0397],\n",
       "          [-0.3502,  0.2463,  0.7457, -0.4609,  0.2204]],\n",
       " \n",
       "         [[ 0.1069, -0.2361,  0.0720, -0.3599, -0.1422],\n",
       "          [-0.2923,  1.0428,  0.4500, -0.1811,  0.0207],\n",
       "          [-0.2012, -0.3692, -0.2832, -0.3149, -0.0870],\n",
       "          [ 0.5086,  0.2375,  0.2408, -0.7849,  0.1771],\n",
       "          [ 0.1452,  0.5633, -0.5820,  1.0265,  0.7818]]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In batches, the channels are in dimension 1\n",
    "#In single images, the channels are in dimension 0\n",
    "#Either way, they are 3rd from the end, i.e. in position -3\n",
    "\n",
    "img_gray_naive = img_t.mean(-3) #Mean over the 3rd from last (i.e. rgb) dimension\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "\n",
    "#Img_gray naive will return a 5x5 tensor- 5 rows, 5 columns. The number therein will be the \"gray value\"\n",
    "#batch_gray_naive returns 2x5x5 tensor- two images with their \"gray\" value\n",
    "img_gray_naive, batch_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126f7d150>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_gray_naive, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.2126, 0.7152, 0.0722]) #Weights has shape 3\n",
    "\n",
    "#Unsqueezed_weights has shape (3,1,1)- applies multiplication to RBG dimension for each of the 5x5 pixels\n",
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1) \n",
    "\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights) #Multiplies R, G, B values by appropriate weight across all pixels in the two images\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1279732d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_gray_weighted, cmap='gray') #Bitmap image with the new weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the same operation using the einsum function\n",
    "img_gray_weighted_fancy = torch.einsum('...chw, c->...hw', img_t, weights) #Use ... to generalise to arbitrary number of leading dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127a97050>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_gray_weighted_fancy, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the einsum feature on the batch\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw, c->...hw', batch_t, weights)\n",
    "#Keep every dimension other than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 5]),\n",
       " tensor([[[ 0.2390, -0.7722,  0.0685,  0.0177, -1.5741],\n",
       "          [-0.1531,  0.5868,  1.0038,  0.1436, -0.0535],\n",
       "          [-1.6050,  0.3852,  0.3344, -0.4731,  0.0804],\n",
       "          [-0.4720,  0.9454, -1.1179, -0.2444, -1.1266],\n",
       "          [-0.1279,  1.1317,  0.5227, -0.2862, -0.0406]],\n",
       " \n",
       "         [[ 0.1871, -0.2527, -0.1051, -0.7100, -0.7797],\n",
       "          [-0.2116,  1.0236,  1.0750, -0.6039,  0.9263],\n",
       "          [-0.3205, -0.3121, -0.5218, -0.5900,  0.1401],\n",
       "          [ 1.4706,  0.4928,  0.9690, -1.0503, -0.9425],\n",
       "          [ 0.4442, -0.6074, -0.1077,  0.7895,  1.3262]]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gray_weighted_fancy.shape, batch_gray_weighted_fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/qqf885v16ps2h__10kf0m2th0000gn/T/ipykernel_62045/2163324119.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/c10/core/TensorImpl.h:1931.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names = ['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names = ['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9474, -0.3339,  0.8896, -0.0669, -0.0911],\n",
      "         [ 1.2896, -0.5316,  1.6678,  0.8266, -0.1269],\n",
      "         [ 1.4261,  0.6560, -1.4613,  0.3156,  0.1560],\n",
      "         [-0.9419, -0.1040,  0.0926, -2.0444,  0.7107],\n",
      "         [ 0.2071,  0.6592, -1.1623,  0.5873,  0.6967]],\n",
      "\n",
      "        [[ 0.5342,  0.1460,  1.6415,  1.1359, -1.4765],\n",
      "         [-0.2158, -2.4447, -1.0646,  1.2959, -0.3867],\n",
      "         [-0.0235,  1.6203,  0.9757,  0.2943,  0.7410],\n",
      "         [ 0.0266,  1.6731,  0.5453, -0.0791, -1.0173],\n",
      "         [ 1.4137, -0.1783,  0.1850,  0.0378, -0.4301]],\n",
      "\n",
      "        [[-2.3538, -1.3923, -1.1282, -2.3586,  0.0555],\n",
      "         [-0.3133, -0.1028, -0.7182, -0.4969,  0.2671],\n",
      "         [ 2.2092, -0.0409,  1.7905, -0.4240,  0.9849],\n",
      "         [-0.8076, -1.3662, -0.5117, -0.3452, -0.9885],\n",
      "         [-0.2870,  2.0360,  0.5162, -0.6286,  0.1478]]],\n",
      "       names=('channels', 'rows', 'columns')) torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "tensor([[[[ 5.0062e-01, -1.2501e+00, -2.7732e-01,  8.1285e-01, -2.3660e+00],\n",
      "          [-5.2976e-01,  6.2282e-01, -1.5704e+00, -8.7260e-02,  2.2722e-01],\n",
      "          [ 1.4160e+00,  5.3296e-01, -1.0560e+00,  2.7322e-01,  1.8064e-01],\n",
      "          [ 2.0427e-01,  2.3236e+00,  2.2123e+00, -1.4864e+00,  2.1949e+00],\n",
      "          [-3.7857e-01,  1.2157e+00,  1.1916e+00, -5.2463e-01,  1.4528e+00]],\n",
      "\n",
      "         [[ 3.2869e-01, -6.0414e-01,  1.0072e-01, -4.3433e-01, -1.5258e+00],\n",
      "          [-1.0970e-01,  5.5240e-01,  1.9289e+00,  2.6869e-01, -1.3466e-01],\n",
      "          [-2.7136e+00,  3.6737e-01,  7.1553e-01, -5.3659e-01,  5.0795e-03],\n",
      "          [-8.6039e-01,  5.2799e-01, -2.4204e+00,  1.9481e-01, -2.2448e+00],\n",
      "          [ 1.6644e-03,  1.4117e+00,  3.0152e-01, -1.7525e-01, -4.5458e-01]],\n",
      "\n",
      "         [[-1.4200e+00, -1.0297e+00,  7.6778e-01,  2.1538e+00,  2.7936e-01],\n",
      "          [ 5.2589e-01,  8.2140e-01, -5.8016e-01, -4.1565e-01, -7.6254e-02],\n",
      "          [ 4.8086e-01,  1.2622e-01,  6.5260e-01, -2.0413e+00,  5.3145e-01],\n",
      "          [ 1.3836e+00,  1.0221e+00,  1.9793e+00, -9.3816e-01,  1.6898e-01],\n",
      "          [-6.7384e-01, -1.8885e+00,  7.4399e-01, -6.8290e-01, -3.3720e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4669e-01, -4.2506e-01, -1.6924e-01, -1.0961e-02,  6.8852e-01],\n",
      "          [-7.3388e-01,  2.5312e+00, -2.9898e-01, -6.2993e-02, -5.3961e-01],\n",
      "          [ 8.6644e-01, -7.3160e-01,  1.7169e-01, -3.7719e-01,  7.8460e-01],\n",
      "          [ 2.4199e-01,  5.8237e-01,  5.5204e-01, -4.6612e-01, -2.3286e-01],\n",
      "          [ 1.3728e+00,  2.9601e+00, -1.4265e+00,  5.8368e-01,  5.8623e-01]],\n",
      "\n",
      "         [[ 2.0107e-01, -2.2071e-01, -1.5077e-01, -9.8056e-01, -1.3150e+00],\n",
      "          [-7.0325e-02,  6.8798e-01,  1.5856e+00, -8.6444e-01,  1.5514e+00],\n",
      "          [-6.1985e-01, -2.0121e-01, -7.5356e-01, -7.2914e-01,  7.5843e-02],\n",
      "          [ 2.0630e+00,  5.5925e-01,  1.3053e+00, -1.2672e+00, -1.4746e+00],\n",
      "          [ 3.4211e-01, -1.7808e+00,  3.4007e-01,  7.5458e-01,  1.6712e+00]],\n",
      "\n",
      "         [[-1.2693e-01, -6.2507e-02,  5.3616e-01, -8.8300e-02,  1.9987e-01],\n",
      "          [-7.2676e-02, -9.0852e-02,  6.3427e-02,  3.8407e-01, -9.4962e-01],\n",
      "          [-8.5007e-01, -1.7474e-01, -2.6761e-01,  1.6152e-01, -1.1213e+00],\n",
      "          [-7.7924e-01, -4.2905e-01, -1.1349e+00, -6.2151e-01,  2.2388e+00],\n",
      "          [-1.2792e+00,  5.1066e-01, -6.5947e-01,  1.7413e+00,  8.8070e-02]]]],\n",
      "       names=(None, 'channels', 'rows', 'columns')) torch.Size([3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(img_named, img_named.shape, img_named.names)\n",
    "print(batch_named, img_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2126]],\n",
       " \n",
       "         [[0.7152]],\n",
       " \n",
       "         [[0.0722]]], names=('channels', 'rows', 'columns')),\n",
       " torch.Size([3, 1, 1]),\n",
       " ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named) #Permutes the weight tensor dimensions until aligned appropriately, and then adds in dimensions as necessary\n",
    "weights_aligned, weights_aligned.shape, weights_aligned.names #Shape is (3,1,1) and has the same names as the img_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels') #Performs the sum over colour channels after appropriate weighting\n",
    "gray_named.shape, gray_named.names #Only has two dimensions, which are named rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.int16)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1,2], [3,4]], dtype=torch.short)\n",
    "\n",
    "double_points.dtype, short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.int16)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using casting instead to enforce the correct data type\n",
    "\n",
    "double_points = torch.ones(10, 2).double()\n",
    "short_points = torch.tensor([[1,2], [3,4]]).short()\n",
    "\n",
    "double_points.dtype, short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(dtype=torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transpose feature in torch\n",
    "a = torch.randn(3,2)\n",
    "a_t = torch.transpose(a, 0, 1) #Exchanges dim0 and dim1\n",
    "\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Zeroing method\n",
    "\n",
    "a = torch.ones(2,3)\n",
    "print(a)\n",
    "print(a.zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stride:  (3, 1)\n",
      "Shape:  torch.Size([3, 3])\n",
      "Offset:  0\n"
     ]
    }
   ],
   "source": [
    "#Shape, offset, stride\n",
    "a = torch.randn(3,3) \n",
    "#shape of the tensor is 3x3. Stride is (3,1), as 3 steps along storage takes you to the next row, and 1 step along storage takes you to the next column\n",
    "print('Stride: ', a.stride())\n",
    "print('Shape: ', a.shape)\n",
    "print('Offset: ', a.storage_offset()) #How far along the storage object is the first element of the matrix stored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2],\n",
      "        [10,  4],\n",
      "        [ 5,  6]])\n",
      "Second Point Storage offset:  2\n"
     ]
    }
   ],
   "source": [
    "#Need to use the clone method to make sure that we aren't accidentally modifying the original tensor\n",
    "points = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "second_point = points[1]\n",
    "second_point[0] = 10 #This will modify the original tensor\n",
    "print(points)\n",
    "print('Second Point Storage offset: ', second_point.storage_offset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "Second Point Storage offset:  0\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "second_point = points[1].clone() #second_point is now a separate tensor, i.e. a clone. Changing its values leaves the original tensor unaffected\n",
    "second_point[0] = 10 #This will NOT modify the original tensor\n",
    "print(points)\n",
    "print('Second Point Storage offset: ', second_point.storage_offset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]]),\n",
       " tensor([[1, 3, 5],\n",
       "         [2, 4, 6]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Contiguous and non-contiguous tensors\n",
    "a = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "b = a.T #Accessing b's storage element in order will not return the original tensor b\n",
    "print(a.is_contiguous(), b.is_contiguous())\n",
    "\n",
    "#Storage objects for the two tensors will be the same\n",
    "print(a.storage())\n",
    "print(b.storage())\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (1, 2))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stride(), b.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "( 1\n",
       "  3\n",
       "  5\n",
       "  2\n",
       "  4\n",
       "  6\n",
       " [torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6],\n",
       " True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_cont = b.contiguous()\n",
    "b_cont.storage(), b_cont.is_contiguous() #New storage object created such that this tensor is in fact contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(19823)\n",
    "\n",
    "points_gpu = torch.randn(400, 400, device='mps') #Metal Performance Shaders\n",
    "points_gpu.device \n",
    "\n",
    "points = torch.randn(400, 400)\n",
    "points.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU computation time:  0.0006060600280761719\n",
      "GPU computation time:  0.0010759830474853516\n"
     ]
    }
   ],
   "source": [
    "#Comparing the computation time\n",
    "\n",
    "ti = time.time()\n",
    "points_cpu_square = points * points\n",
    "tf = time.time()\n",
    "dt_cpu = tf-ti\n",
    "\n",
    "ti = time.time()\n",
    "points_gpu_square = points_gpu * points_gpu\n",
    "tf = time.time()\n",
    "dt_gpu = tf-ti\n",
    "\n",
    "print('CPU computation time: ', dt_cpu)\n",
    "print('GPU computation time: ', dt_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can also save a tensor directly into a file\n",
    "torch.save(points, 'points.t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
