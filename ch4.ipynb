{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/qqf885v16ps2h__10kf0m2th0000gn/T/ipykernel_58475/2568715981.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread('images/rainbow_alaska.jpeg') #Produces a numpy array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(630, 1200, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn an image into an array\n",
    "img_arr = imageio.imread('images/rainbow_alaska.jpeg') #Produces a numpy array\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([630, 1200, 3]),\n",
       " torch.Size([3, 630, 1200]),\n",
       " torch.Size([3, 630, 1200]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.from_numpy(img_arr) #Creates a tensory from a numpy array\n",
    "out = img.permute(2,0,1)\n",
    "img.shape, out.shape, out[:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up batch, with a size of 3\n",
    "batch_size = 3 #Number of images\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8) #3 images, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for reading multiple images in .png format from a directory\n",
    "image_directory = '/images'\n",
    "image_path = os.getcwd() + image_directory\n",
    "\n",
    "images = [name for name in os.listdir(image_path) if os.path.splitext(name)[-1] == '.png'] #Retrieve files in image directory\n",
    "\n",
    "for i, filename in enumerate(images):\n",
    "    img_arr = imageio.imread(os.path.join(image_directory,filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1) #Turns dimension 0 into colour channel\n",
    "    img_t = img_t[:3] #Makes sure that we only have 3 entries in colour dimension (i.e. makes sure we don't have alpha values or something)\n",
    "    batch[i] = img_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalising Data</h3>\n",
    "<ul>\n",
    "<li>Best performance of Neural Network occurs when data in range [0,1]</li>\n",
    "<li>Max representatble value in 8-bit format is 255</li>\n",
    "<li>Divide each pixel value by 255</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "\n",
    "n_channels = batch.shape[1] #Size of the 1th dimension of batch (i.e. the number of colour channels, which should be 3)\n",
    "\n",
    "#Cycle through each colour and compute the average\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c]) #Mean value of the selected colour channel across all images and all pixels\n",
    "    std = torch.std(batch[:,c]) #Standard deviation for the colour\n",
    "    batch[:,c] = (batch[:,c]-mean)/std #Centred at 0 with unit standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Wine Data</h2>\n",
    "In the following section, we take a look at a csv file containing attributes of a number of wines (acidity, sulfur level, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fixed acidity', 'volatile acidity', 'citric acid',\n",
       "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
       "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract wine data from the .csv\n",
    "wine_csv = pd.read_csv('ch4data/winequality-white.csv', delimiter=';')\n",
    "data = torch.tensor(wine_csv.iloc[:, :-1].values) #All information about the wine, with the final score extracted\n",
    "target = torch.tensor(wine_csv.iloc[:, -1].values) #Get the last column, which contains the score\n",
    "\n",
    "attribute_list = wine_csv.columns.values[:-1]\n",
    "attribute_list #the 11 attributes without the quality score\n",
    "\n",
    "#data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute mean value and variance of each of the 11 wine attributes\n",
    "data_mean = torch.mean(data, dim=0) #dim=0 i.e. compute COLUMN average for each row. dim=1 would compute ROW average for each column\n",
    "data_var = torch.var(data, dim=0)\n",
    "\n",
    "#Produce normalised data, with mean at 0 and stddev length 1\n",
    "data_normalized = (data - data_mean)/torch.sqrt(data_var)\n",
    "\n",
    "#data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 11]), torch.Size([3818, 11]), torch.Size([1060, 11]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use advanced indexing to get the bad wines, mid wines, and good wines\n",
    "bad_data = data[target <= 3] #Wine score of 3 or less is bad\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data = data[target>=7] #Wine score greater than or equal to 7 is good!\n",
    "\n",
    "bad_data.shape, mid_data.shape, good_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last cell told us that there were 20 bad wines. We have their data in a new tensor called <code>bad_data</code>, with dimensions <code>20x11</code>- 20 bad wines with 11 attributes each.\n",
    "There are 3818 \"mid\" wines, and 1060 \"good\" wines. Let's take a look at their <b>mean scores</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.6000e+00, 3.3325e-01, 3.3600e-01, 6.3925e+00, 5.4300e-02, 5.3325e+01,\n",
       "         1.7060e+02, 9.9488e-01, 3.1875e+00, 4.7450e-01, 1.0345e+01],\n",
       "        dtype=torch.float64),\n",
       " tensor([6.8869e+00, 2.8153e-01, 3.3644e-01, 6.7051e+00, 4.7841e-02, 3.5424e+01,\n",
       "         1.4183e+02, 9.9447e-01, 3.1808e+00, 4.8707e-01, 1.0265e+01],\n",
       "        dtype=torch.float64),\n",
       " tensor([6.7251e+00, 2.6535e-01, 3.2606e-01, 5.2615e+00, 3.8160e-02, 3.4550e+01,\n",
       "         1.2525e+02, 9.9241e-01, 3.2151e+00, 5.0014e-01, 1.1416e+01],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean attribute values for each attribute\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "bad_mean, mid_mean, good_mean #Should each give lists with 11 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresheet = {\n",
    "    'Attribute':attribute_list,\n",
    "    'Bad Mean':bad_mean,\n",
    "    'Mid Mean':mid_mean,\n",
    "    'Good Mean':good_mean\n",
    "}\n",
    "\n",
    "scoresheet_df = pd.DataFrame(scoresheet)\n",
    "scoresheet_df.to_csv('ch4data/scorecard.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell, we saved a \"scorecard\" showing the average attribute value for each category of wine. We can see by eye that bad wines typically have a higher acidity and sulfur dioxide content than good wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2727), tensor(3258))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at starting to set threshold values of sulfur dioxide content\n",
    "total_sulfur_threshold = mid_mean[6] #Set threshold value for sulfur content as the mean sulfur content for mid wines\n",
    "total_sulfur_data = data[:,6] #All wines, but only their sulfur content- should be a single-dim tensor with length = no. of wines\n",
    "\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold) #Compares each wine's sulfur content to the threshold\n",
    "actual_indexes = target > 5 #Indices of wines with wines of scores over 5\n",
    "\n",
    "#How many wines are we predicting to be good vs how many actually have a score over 5?\n",
    "predicted_indexes.sum(), actual_indexes.sum() #We see from the output that we are underestimating the \"good wine\" number by about 500 wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bike Sharing in Washington D.C.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each row of the .csv file gives a different hour of the data\n",
    "bikes_numpy = np.loadtxt(\n",
    "    'ch4data/hour-fixed.csv', \n",
    "    delimiter=',', \n",
    "    dtype=np.float32, \n",
    "    skiprows=1,\n",
    "    converters={1: lambda x: float(x[8:10])} #Converts dates to just day of the month using 2 of the numbers in the date\n",
    "    )\n",
    "\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes.size(), bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1]) #Rearrange tensor with no memory cost (uses same storage space as bikes)\n",
    "#bikes.shape[1] = 17 (number of columns in tensor)\n",
    "#24 hours in a day- EACH ROW IS NOW ONE DAY\n",
    "\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1,2)\n",
    "daily_bikes.shape, daily_bikes.stride() #Bikes is now Days x Parameters x Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long() #Gives us the first 24 hours of data, i.e. the first day Cast to float64\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4) #Empty tensor with number of rows equal to number of hours in the day\n",
    "first_day[:, 9] #Weather status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add ones into the weather_onehot tensor\n",
    "weather_onehot.scatter_(\n",
    "    dim = 1,\n",
    "    index = first_day[:,9].unsqueeze(1).long() - 1, #Specifies index for one-hot encoding\n",
    "    value = 1.0\n",
    ")\n",
    "#One-hot: 0, 1, 2, 3- four weather categories\n",
    "#Weather rating 1 gives us a vector [1,0,0,0]\n",
    "#Weather rating 2 gives us a vector [0,1,0,0] etc.\n",
    "\n",
    "\n",
    "weather_onehot #24 rows, 4 columns. Each row is a row vector encoding weather in a one-hot manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "           0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "          16.0000]]),\n",
       " tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "           0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "          16.0000,  1.0000,  0.0000,  0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate the weather_onehot vector to the original dataset\n",
    "\n",
    "bikes[:24][:1], torch.cat((bikes[:24], weather_onehot), 1)[:1] #Last four columns give the onehot weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've taken the first 24hrs of data for the bike system, and added four columns at the side of the tensor- these four columns in each row represent the weather vector produced by one-hot encoding. There is another way of doing this in a bit of a shorter manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new tensor with 24 rows (one for each hour), 4 columns (for the onehot vector), and a depth\n",
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "\n",
    "#Dimension 0: number of days (730)\n",
    "#Dimension 1: 4 spaces for onehot vector encoding\n",
    "#DImension 2: 24 entries long one for each hour\n",
    "daily_weather_onehot.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 24])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(\n",
    "    dim = 1, #Choose the first dimension as this is 4 spaces long\n",
    "    index = daily_bikes[:, 9, :].unsqueeze(1).long() - 1, #Specifies index for one-hot encoding, subtract 1 cause 0 indexing\n",
    "    value = 1.0\n",
    ")\n",
    "\n",
    "daily_bikes[:, 9, :].shape \n",
    "#730x24- 730 days, 24 hours in each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 4, 24]),\n",
       " tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.shape, daily_weather_onehot\n",
    "#730(days) x 4(dimension of weather onehot vector) x 24(hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([730, 17, 24])\n",
      "torch.Size([730, 21, 24])\n"
     ]
    }
   ],
   "source": [
    "print(daily_bikes.shape)\n",
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)\n",
    "print(daily_bikes.shape) #Gain 4 more columns, which is the dimension of the onehot weather vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Temperature data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 24])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "temp.shape #Each row is a 24-long vector, where each entry is the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2400, 0.2200, 0.2200,  ..., 0.4000, 0.4000, 0.4600],\n",
      "        [0.4600, 0.4400, 0.4200,  ..., 0.2600, 0.2400, 0.2200],\n",
      "        [0.2200, 0.2000, 0.2000,  ..., 0.1800, 0.1400, 0.1800],\n",
      "        ...,\n",
      "        [0.2400, 0.2400, 0.2400,  ..., 0.2800, 0.2600, 0.2600],\n",
      "        [0.2600, 0.2600, 0.2600,  ..., 0.2000, 0.2000, 0.2000],\n",
      "        [0.1800, 0.1800, 0.1600,  ..., 0.2600, 0.2600, 0.2600]])\n",
      "tensor([[-1.3213, -1.4248, -1.4248,  ..., -0.4932, -0.4932, -0.1827],\n",
      "        [-0.1827, -0.2862, -0.3897,  ..., -1.2178, -1.3213, -1.4248],\n",
      "        [-1.4248, -1.5284, -1.5284,  ..., -1.6319, -1.8389, -1.6319],\n",
      "        ...,\n",
      "        [-1.3213, -1.3213, -1.3213,  ..., -1.1143, -1.2178, -1.2178],\n",
      "        [-1.2178, -1.2178, -1.2178,  ..., -1.5284, -1.5284, -1.5284],\n",
      "        [-1.6319, -1.6319, -1.7354,  ..., -1.2178, -1.2178, -1.2178]])\n"
     ]
    }
   ],
   "source": [
    "#Normalise to a gaussian with a mean at 0 and a std of 1\n",
    "print(temp)\n",
    "std = torch.std(temp)\n",
    "mu = torch.mean(temp)\n",
    "temp = (temp - mu)/std\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Processing Text</h1>\n",
    "Can fine-grain text files down to the single-letter or single-word level- for this, can use a text file of Pride & Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the text file and read\n",
    "with open('ch4data/1342.txt', encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#Separate into lines\n",
    "lines = text.split('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
